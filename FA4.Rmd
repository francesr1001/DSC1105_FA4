---
title: "DSC_1105_FA4"
author: "Frances Aneth Rosales"
date: "`r Sys.Date()`"
output:
  html_document:
    css: FA4.css
  pdf_document: default
---
<style>
  body {
    text-align: justify;
  }
</style>

<br>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


```
<br><br>

<br><br>

# PLOTTING 

<br><br>

Click to Hide/Show Plots

<button onclick="hideoutput()" style="background: #e8ccd7;"> 
HIDE/SHOW
</button>
<div id="codeinputhere" style="display:block;">


# 1
<b>  Create a histogram on the diamonds dataset, for example with

ggplot() + geom_histogram(aes(x = carat), data = diamonds) </b>
```{r r_1}
library(tidyverse)
library(car)
library(ggplot2)

library(readr)
mortality_file <- read_csv("C:/Users/asus/Documents/ALL FEU FILES/FEU FOLDER 6/DSC_1105 Explo/FA4/mortality_by_latitude.csv")

summary(mortality_file)

```




</div>
<script>
function hideoutput() {
  var x = document.getElementById("codeinputhere");
  if (x.style.display === "block") {
    x.style.display = "none";
    
    
  } else {
    x.style.display = "block";
  }
}
</script>

<br><br><br>

<h3>
1. Using the Mortality by Latitude data Download Mortality by Latitude data, make a plot of mortality index against mean average temperature. Is it hollow up or hollow down? Try to identify a transformation of one of the variables that will straighten out the relationship, and make a plot of the residuals to check for any remaining patterns.
</h3>
<br><br>

# Using the most common transformation, the log.

The main reason we gave was that it often made positive data more normal.
Taking logs amounts to changing the units of the data in such a way that equal differences now mean equal multiplicative factors. This simplifies the interpretation of the measurement scale because addition is easier than multiplication.
Some statisticians will go as far as to recommend log transforming positive data by default, though by the end of Cleveland’s chapter 2, we’ll see an example where that backfires.


```{r r_2}

log_in_temp <- log(mortality_file$temperature)

ggplot(mortality_file, aes(x = log_in_temp, y = mortality_index)) +
  geom_point() +
  labs(title = "Transformed Mortality Index vs Log of Mean Average Temperature",
       x = "Log of Mean Average Temperature",
       y = "Mortality Index")
```

<br>

# Straight Line
```{r r_w}

model <- lm(mortality_index ~ log_in_temp, data = mortality_file)
plot(model, which = 1) 
```
<br><br><br>

<h3>
Analyzing the ploting, the index of temperature increases, therefore, <b> Hollow Up </b>. 
</h3>
<br><br><br>


<h3>
2. Using the same subset of the diamonds dataset, make a plot of log price as a function of carat with a loess smoother. Try several values for the span and degree arguments and comment briefly about your choice.

</h3>
```{r r_3}

library(ggplot2)
sample_diamonds <- diamonds[1:1500, ]
ggplot(sample_diamonds, aes(x = carat, y = log(price))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess", se = FALSE, span = 0.3, color = "blue") +
  labs(title = "Log Price vs Carat with Loess Smoother",
       x = "Carat",
       y = "Log Price") +
  theme_minimal()

```
<br><br><br>
Trying Values  0.5,0.8,0.9
```{r r_4}

subset_diamonds <- diamonds[1:1500, ]

# Vector of values for span
span_values <- c( 0.5,0.8,0.9)

# Shortened code
for (span in span_values) {
  loess_model <- loess(log(price) ~ carat, data = subset_diamonds, span = span, degree = 2)
  loess_data <- cbind(subset_diamonds, predicted_values = predict(loess_model, newdata = data.frame(carat = subset_diamonds$carat)))
  p <- ggplot(loess_data, aes(x = carat, y = log(price))) +
    geom_point(alpha = 0.5) +
    geom_line(aes(y = predicted_values), color = "red") +
    labs(title = paste("Loess Smoother (Span =", span, ")"), x = "Carat", y = "Log Price") +
    theme_minimal()
  cat("For span =", span, ": Good balance between smoothing and capturing local patterns.\n")
  print(p)
}


```


<br><br><br><br>

<h3>
3. Compare the fit of the loess smoother to the fit of the polynomial + step function regression using a plot of the residuals in the two models. Which one is more faithful to the data? 
</h3>   

```{r r_ss}


library(ggplot2)

subset_diamonds <- diamonds[1:1500, ]

loess_model <- loess(log(price) ~ carat, data = subset_diamonds, span = 0.5)

lm_model <- lm(log(price) ~ poly(carat, 3) + cut, data = subset_diamonds)

subset_diamonds$residuals_loess <- residuals(loess_model)
subset_diamonds$residuals_lm <- residuals(lm_model)

ggplot(subset_diamonds, aes(x = carat)) +
  geom_point(aes(y = residuals_loess), color = "blue", alpha = 0.8) +
  geom_point(aes(y = residuals_lm), color = "red", alpha = 0.8) +
  labs(title = "Comparison of Residuals",
       x = "Carat",
       y = "Residuals") +
  theme_minimal()


#
```
# Analysis
As shown, the residual of for Loess Model for BLUE POINT and Poly Model for RED POINT do not spread together on some point, however as shown in the plotting <b> loess data </b> spreads more and constantly touches the 0.0 deviate which is a potential for a shortcomings, thus <b> more faithful</b>.